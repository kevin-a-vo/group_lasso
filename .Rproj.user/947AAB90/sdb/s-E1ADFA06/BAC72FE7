{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Group_Lasso\"\nauthor: \"Kevin Vo\"\ndate: \"2/13/2017\"\noutput: html_document\n---\n# Group Lasso Tutorial\n*Note: This tutorial is based off of royr2. I'm using the example and appending my own notes for the sake of my understanding*\n\n## Preprocessing\n\nWe first load install the necessary libraries and load them in. We also load in the csv files and format the dates.\n```{r results='hide', message=FALSE, warning=FALSE}\nlibrary(gglasso)\nlibrary(RColorBrewer)\nlibrary(zoo)\n\nhist=read.csv(\"historical_data.csv\")\nproj=read.csv(\"projections.csv\")\n\nhist=data.frame(Date=as.Date(as.yearqtr(hist[,1])),hist[,-1])\nproj=data.frame(Date=proj[,1],proj[,-1])\n```\n\nWe now make a plot of unemployment rate over time.\n```{r makeplot}\nplot(y=hist$Unemployment.Rate,x=hist$Date,main=\"Unemployment\",lwd=2,col=\"slateblue\",type=\"l\",xlab=\"Time\",ylab=\"Unemployment %\")\ngrid()\n```\n\nThe data makes sense so far. We expect to see high unemployment during the recession years and a recovery in the following years. Let's take a look at the column names of the hist data frame.\n```{r names}\nnames(hist)\n```\n\nWe now clean the data a bit. We remove Dates and Unemployment from the model matrix. Here we also define the groups, with the grp vector. Group 1 will be the first three variables. Group 2 will be the next four variables and so fourth. \n```{r cleandata}\nX=hist[,c(-1,-4)]\nX=as.matrix(X)\nY=hist[,4]\ngrp=c(1,1,1,2,2,2,2,3,3,3,3,4,4)\nfit=gglasso(x=X,y=Y,group=grp,loss='ls')\ncoef.mat=fit$beta\n```\n\nNow we identify when the groups enter the model.\n```{r identify}\n#Group1 enters the equation\ng1=max(which(coef.mat[1,]==0))\n\n#Group2 enters the equation\ng2=max(which(coef.mat[4,]==0))\n\n#Group3 enters the equation\ng3=max(which(coef.mat[8,]==0))\n\n#Group4 enters the equation\ng4=max(which(coef.mat[12,]==0))\n\n#Coefficient Plot. Let's also use some nice colors\n\ncols=brewer.pal(5,name=\"Set1\")\n\nplot(fit$b0,main=\"Coefficient vs Step\",\n     ylab=\"Intercept\",xlab=\"Step (decreasing Lambda =>)\",\n     col=cols[1],\n     xlim=c(-1,100),\n     ylim=c(5,max(fit$b0)),\n     type=\"l\",lwd=4)\ngrid()\npar(new=T)\n\nx=c(g1,g2,g3,g4)\ny=c(fit$b0[g1],fit$b0[g2],fit$b0[g3],fit$b0[g4])\n\nplot(x=x,y=y,pch=13,lwd=2,cex=2,col=cols[-1],\n     xlim=c(-1,100),ylim=c(5,max(fit$b0)),\n     xaxt='n',yaxt='n',xlab=\"\",ylab=\"\")\n\nlmda=round(fit$lambda[c(g1,g2,g3,g4)],2)\ntext(x=x-0.5,y=y+0.1,labels=c(\"Group1\",\"Group2\",\"Group3\",\"Group4\"),pos=3,cex=0.9)\ntext(x=x-0.5,y=y-0.1,labels=paste(\"Lambda\\n=\",lmda),pos=1,cex=0.8)\n```\n\nO.K. here's the question on the blocks. In a group lasso setting, can variables within a group be zero and nonzero for a given lambda. According to Michael Lim's Stanford Dissertation he states that \"if an estimate $\\beta_i$ is nonzero, where $i$ denotes group $i$, then all its components are usually nonzero\". We see this here in \"coef.mat\".\n```{r viewcoeff}\ncoef.mat[, 11:16]\n```\nLooking at coef.mat, we see that group 4 stays in the whole the time. Group 3 enters in s13. Group 2 subsequently enters in s15. There are no cases where only a select set of variables from a group enter or exit. They enter and exit as a *group*.\n\n## Group Lasso vs. Lasso\n\nThe lasso uses an L1-norm penalty. The L1-norm penalty is defined as\n$$\nS = \\sum_{i=1}^n |y_i - f(x_i)|\n$$\nCompare this to the L2-norm penalty. This is probably a loss function that many of you are familiar with. It is defined as follows.\n$$\nS = \\sum_{i=1}^n (y_i - f(x_i))^2\n$$\nIf you substitute the loss function with L2-norm in lasso you get ridge regression. The grouped lasso minimizes the following convex criterion. Here we have $L$ groups of variables. The feature matrix for group $i$ is denoted by $\\textbf{X}$. Let $y$ be the vector of observations. $\\beta_j$ for $j = 1, ..., p$. The parameter $\\lambda$ controls the amount of regularization, with larger values implying more regularization. When $\\lambda$ is large enough, all the coefficients will be estimated as zero. The $\\gamma$ allows each group to be penalized to different extents, which allows us to penalize some groups more (or less) than others. Please note that the L2 penalty is not squared.\n$$\n\\min_{\\beta \\in R^p}\\frac{1}{2}\\big(||y - \\beta_0\\textbf{1} - \\sum_{l= 1}^L\\textbf{X}_l\\beta_l||_2^2 + \\lambda\\sum_{l = 1}^L \\gamma_l ||\\beta_l||_2 \\big)\n$$\nNote: Group lasso does not monotonically decrease groups to zero. Groups and enter and exit the model.\n\nSources\n\n1. http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/\n\n2. http://web.stanford.edu/~hastie/THESES/Michael_Lim.pdf\n\n3. http://royr2.github.io/2014/04/15/GroupLasso.html\n\n4. http://statweb.stanford.edu/~tibs/stat315a/LECTURES/morelasso.pdf",
    "created" : 1487051607406.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1239985406",
    "id" : "BAC72FE7",
    "lastKnownWriteTime" : 1487059063,
    "last_content_update" : 1487059063685,
    "path" : "~/Documents/group_lasso/group_lasso.Rmd",
    "project_path" : "group_lasso.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}